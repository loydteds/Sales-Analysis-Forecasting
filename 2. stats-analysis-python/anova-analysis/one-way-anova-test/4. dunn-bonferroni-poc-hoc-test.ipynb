{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            group1           group2          p-adj  reject\n",
      "0        Furniture        Furniture   1.000000e+00   False\n",
      "1        Furniture  Office Supplies  1.534319e-138    True\n",
      "2        Furniture       Technology   5.207264e-02   False\n",
      "3  Office Supplies        Furniture  1.534319e-138    True\n",
      "4  Office Supplies  Office Supplies   1.000000e+00   False\n",
      "5  Office Supplies       Technology  2.001982e-154    True\n",
      "6       Technology        Furniture   5.207264e-02   False\n",
      "7       Technology  Office Supplies  2.001982e-154    True\n",
      "8       Technology       Technology   1.000000e+00   False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import plotly.express as px\n",
    "from scipy.stats import levene, bartlett, f_oneway, norm\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:\\\\Users\\\\loydt\\\\Downloads\\\\Projects\\\\Superstore Sales Dataset.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Filter the big four states generating higher sales\n",
    "states_of_interest = ['Washington', 'California', 'New York', 'Florida', 'Pennsylvania']\n",
    "state_data = data[data['State'].isin(states_of_interest)]\n",
    "\n",
    "# Extract relevant columns and create a deep copy to avoid SettingWithCopyWarning\n",
    "high_sales_states = state_data[['Segment', 'State', 'City', 'Region', 'Ship Mode', 'Order Date', 'Category', 'Sub-Category', 'Product Name', 'Sales']].copy()\n",
    "\n",
    "# Take logarithm of the Sales column, ensuring non-positive values are handled\n",
    "high_sales_states['log_sales'] = high_sales_states['Sales'].apply(lambda x: math.log(x) if x > 0 else None)\n",
    "\n",
    "# Check for null values in 'log_sales' after transformation\n",
    "if high_sales_states['log_sales'].isnull().any():\n",
    "    print(\"Warning: There are non-positive sales values that have been transformed to NaN.\")\n",
    "\n",
    "# Create a DataFrame with 'log_sales' and 'Category'\n",
    "dunn_data = high_sales_states[['log_sales', 'Category']].dropna()  # Drop NaN values for valid analysis\n",
    "\n",
    "# Conduct Dunn's Test\n",
    "dunn_results = sp.posthoc_dunn(dunn_data, val_col='log_sales', group_col='Category', p_adjust='bonferroni')\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "dunn_results_df = dunn_results.stack().reset_index()\n",
    "dunn_results_df.columns = ['group1', 'group2', 'p-adj']\n",
    "\n",
    "# Create a 'reject' column based on the adjusted p-value\n",
    "dunn_results_df['reject'] = dunn_results_df['p-adj'] < 0.05\n",
    "\n",
    "# Display the results\n",
    "print(dunn_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
